{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f591283",
   "metadata": {},
   "source": [
    "# Kerry Ronayne, DS3002 Project #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208c615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necssary packages for the code (if needed, install on device)\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05e7fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the necessary credentials-- the host_name to use for connection strings in later functitons, the different\n",
    "### ports to refer from the jupyter notebook to the device versions of MongoDB and MySQl, the username and \n",
    "###password to access/make changes on Mongo and MySQL, as well as the namees for the database names of the\n",
    "### created mongo and MySQL databasees\n",
    "\n",
    "host_name = \"localhost\"\n",
    "ports = {\"mongo\" : 27017, \"mysql\" : 3306}\n",
    "\n",
    "user_id = \"root\"\n",
    "pwd = \"%\"\n",
    "\n",
    "src_dbname = \"project_2\" #what create in mongo\n",
    "dst_dbname = \"project_2_back2sql\" #destination db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ccb5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define useful functions from class notes and lecture:\n",
    "## \"get_sql_dataframe\" connects jupyter to the MySQL databse, useful for verifying that a given database was in fact passed\n",
    "### into MySQL and for later referencing the output of a given query (I used it in the report section to pass new\n",
    "### queries through python in SQL language to generate general statistics about the data set)\n",
    "\n",
    "## \"get_mongo_dataframe\" connects jupyter to MongoDB, extracting a collection or document from Mongo and converting it\n",
    "### to a pandas dataframe to then manipulate within the python language and eventually send to SQL\n",
    "\n",
    "## \"set_dataframe\" connects jupter again to MySQL, though this time uses the DF from the mongo function^^ to send\n",
    "### that information to SQL into a database into new tables\n",
    "\n",
    "def get_sql_dataframe(user_id, pwd, host_name, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "def get_mongo_dataframe(user_id, pwd, host_name, port, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB, with or without authentication credentials'''\n",
    "    if user_id and pwd:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db_name)\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "        client = pymongo.MongoClient(conn_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query))) #passing in query\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    \n",
    "    return dframe #gives back data from mongo db query in pandas DF\n",
    "\n",
    "def set_dataframe(user_id, pwd, host_name, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e86f9",
   "metadata": {},
   "source": [
    "### Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55ced3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MongoClient.close of MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Populate the converted JSON file in Mongo by creating a client connection, loadining in the JSON file, and using the\n",
    "## 'insert_many' function to then insert the loaded JSON file into Mongo.\n",
    "\n",
    "#Dim Customers\n",
    "\n",
    "conn_str = f\"mongodb://{host_name}:{ports['mongo']}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]\n",
    "\n",
    "customers = db.customers\n",
    "\n",
    "with open('dim_customers.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "\n",
    "customers.insert_many(file_data)\n",
    "\n",
    "client.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d371d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MongoClient.close of MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dim Location\n",
    "\n",
    "conn_str = f\"mongodb://{host_name}:{ports['mongo']}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]\n",
    "\n",
    "location = db.location\n",
    "\n",
    "with open('dim_locations.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "\n",
    "location.insert_many(file_data)\n",
    "\n",
    "client.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6051772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MongoClient.close of MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dim Films\n",
    "conn_str = f\"mongodb://{host_name}:{ports['mongo']}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]\n",
    "\n",
    "films = db.films\n",
    "\n",
    "with open('dim_films.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "\n",
    "films.insert_many(file_data)\n",
    "\n",
    "client.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18474541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MongoClient.close of MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fact Table\n",
    "conn_str = f\"mongodb://{host_name}:{ports['mongo']}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]\n",
    "\n",
    "facts = db.facts\n",
    "\n",
    "with open('fact_table.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "\n",
    "facts.insert_many(file_data)\n",
    "\n",
    "client.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e582bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MongoClient.close of MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batches\n",
    "conn_str = f\"mongodb://{host_name}:{ports['mongo']}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]\n",
    "\n",
    "batch1 = db.batch1\n",
    "with open('batch1.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "batch1.insert_many(file_data)\n",
    "\n",
    "batch2 = db.batch2\n",
    "with open('batch2.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "batch2.insert_many(file_data)\n",
    "\n",
    "batch3 = db.batch3\n",
    "with open('batch3.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "batch3.insert_many(file_data)\n",
    "\n",
    "batch4 = db.batch4\n",
    "with open('batch4.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "batch4.insert_many(file_data)\n",
    "\n",
    "batch5 = db.batch5\n",
    "with open('batch5.json') as openfile:\n",
    "    file_data = json.load(openfile)\n",
    "batch5.insert_many(file_data)\n",
    "\n",
    "client.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05e2de",
   "metadata": {},
   "source": [
    "# Turning Mongo to DF to send to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a328a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new project-specific database in MySQL by creating a connection with the sql alchemy package. If it has\n",
    "## already been created, the exception will note that.\n",
    "\n",
    "try:\n",
    "    exec_sql = f\"CREATE DATABASE `{dst_dbname}`;\"\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    sqlEngine.execute(exec_sql)\n",
    "    sqlEngine.execute(f\"USE {dst_dbname};\")\n",
    "except:\n",
    "    print(\"This database already exists. Either drop the scheme in MySQL or move on to the next cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e51d01",
   "metadata": {},
   "source": [
    "## General Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52ce5484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_key</th>\n",
       "      <th>rental_key</th>\n",
       "      <th>inventory_key</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>length</th>\n",
       "      <th>rental_date</th>\n",
       "      <th>rental_duration</th>\n",
       "      <th>rental_rate</th>\n",
       "      <th>replacement_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>2006</td>\n",
       "      <td>86</td>\n",
       "      <td>2005-07-08 19:03:15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>20.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607</td>\n",
       "      <td>11433.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>2006</td>\n",
       "      <td>86</td>\n",
       "      <td>2005-08-02 20:13:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>20.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   facts_key  rental_key  inventory_key             title  release_year  \\\n",
       "0        606      4863.0              1  ACADEMY DINOSAUR          2006   \n",
       "1        607     11433.0              1  ACADEMY DINOSAUR          2006   \n",
       "\n",
       "   length          rental_date  rental_duration  rental_rate  replacement_cost  \n",
       "0      86  2005-07-08 19:03:15                6         0.99             20.99  \n",
       "1      86  2005-08-02 20:13:10                6         0.99             20.99  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This does the same extracting from mongo as the previous cell, only doing so with the manual season collectiton\n",
    "query = {}\n",
    "port = ports[\"mongo\"]\n",
    "collection = \"facts\"\n",
    "\n",
    "df_facts = get_mongo_dataframe(None, None, host_name, port, src_dbname, collection, query)\n",
    "df_facts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccc91f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending the Pandas dataframes to mySQL using the 'set_dataframe' function in class.\n",
    "\n",
    "dataframe = df_facts\n",
    "table_name = 'fact_table_overview'\n",
    "primary_key = 'facts_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "set_dataframe(user_id, pwd, host_name, dst_dbname, dataframe, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "397fae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_key</th>\n",
       "      <th>rental_key</th>\n",
       "      <th>inventory_key</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>length</th>\n",
       "      <th>rental_date</th>\n",
       "      <th>rental_duration</th>\n",
       "      <th>rental_rate</th>\n",
       "      <th>replacement_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>2006</td>\n",
       "      <td>86</td>\n",
       "      <td>2005-07-08 19:03:15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>20.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607</td>\n",
       "      <td>11433.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>2006</td>\n",
       "      <td>86</td>\n",
       "      <td>2005-08-02 20:13:10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>20.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   facts_key  rental_key  inventory_key             title  release_year  \\\n",
       "0        606      4863.0              1  ACADEMY DINOSAUR          2006   \n",
       "1        607     11433.0              1  ACADEMY DINOSAUR          2006   \n",
       "\n",
       "   length          rental_date  rental_duration  rental_rate  replacement_cost  \n",
       "0      86  2005-07-08 19:03:15                6         0.99             20.99  \n",
       "1      86  2005-08-02 20:13:10                6         0.99             20.99  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying in SQL\n",
    "sql_facts = \"SELECT * FROM project_2_back2sql.fact_table_overview;\"\n",
    "df_facts = get_sql_dataframe(user_id, pwd, host_name, dst_dbname, sql_facts)\n",
    "df_facts.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
